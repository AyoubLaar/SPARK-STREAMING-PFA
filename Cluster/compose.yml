version: "3.8"

services:
  elasticsearch:
    container_name: elasticsearch
    image: docker.elastic.co/elasticsearch/elasticsearch:8.7.1
    # 8.x
    environment:
      [
        "CLI_JAVA_OPTS=-Xms2g -Xmx2g",
        "bootstrap.memory_lock=true",
        "discovery.type=single-node",
        "xpack.security.enabled=false",
        "xpack.security.enrollment.enabled=false",
      ]
    ports:
      - 9200:9200
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    deploy:
      resources:
        limits:
          cpus: "2.0"
        reservations:
          cpus: "1.0"

  kibana:
    image: docker.elastic.co/kibana/kibana:8.7.1
    container_name: kibana
    environment:
      XPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY: d1a66dfd-c4d3-4a0a-8290-2abcb83ab3aa
    ports:
      - 5601:5601
    deploy:
      resources:
        limits:
          cpus: "2.0"
        reservations:
          cpus: "1.0"

  zookeeper:
    image: wurstmeister/zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"

  kafka:
    image: wurstmeister/kafka
    container_name: kafka
    ports:
      - "9093:9093"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka:9092,OUTSIDE://localhost:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_LISTENERS: INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9093
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_CREATE_TOPICS: "tweets"

  spark-master:
    container_name: da-spark-master
    build: .
    image: spark:3.4.3
    entrypoint: ["./entrypoint.sh", "master"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080"]
      interval: 5s
      timeout: 3s
      retries: 3
    volumes:
      - ./book_data:/opt/spark/data
      - ./spark_apps:/opt/spark/apps
      - spark-logs:/opt/spark/spark-events
    env_file:
      - .env.spark
    ports:
      - "9090:8080"
      - "7077:7077"

  spark-history-server:
    container_name: da-spark-history
    image: spark:3.4.3
    entrypoint: ["./entrypoint.sh", "history"]
    depends_on:
      - spark-master
    env_file:
      - .env.spark
    volumes:
      - spark-logs:/opt/spark/spark-events
    ports:
      - "18080:18080"

  spark-worker:
    image: spark:3.4.3
    entrypoint: ["./entrypoint.sh", "worker"]
    depends_on:
      - spark-master
    env_file:
      - .env.spark
    volumes:
      - ./book_data:/opt/spark/data
      - ./spark_apps:/opt/spark/apps
      - spark-logs:/opt/spark/spark-events

volumes:
  spark-logs:
